{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as tfs\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "from torch.nn import functional as F\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['background','apple', 'banana', 'bread', 'bun', 'doughnut', 'egg', 'fired_dough_twist', 'grape', 'lemon', 'litchi', 'mango', 'mix', \n",
    "          'mooncake', 'orange', 'pear', 'peach', 'plum', 'qiwi', 'sachima', 'tomato', 'coin']\n",
    "\n",
    "# RGB color for each class\n",
    "colormap = [[0,0,0],[255,0,0],[227, 207, 87], [165, 42, 42], [255, 245, 238],\n",
    "            [255, 215, 0],[205,133,63],[139,69,19],[128,0,128],[255,127,132],\n",
    "            [255,69,0],[255,255,0],[215,105,30],[255,165,0],\n",
    "            [255,227,132],[220,20,60],[139,0,0],[34,139,34],\n",
    "            [255,255,240],[255,99,71],[0, 0, 255]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2lbl = np.zeros(256**3) # 每个像素点有 0 ~ 255 的选择，RGB 三个通道\n",
    "for i,cm in enumerate(colormap):\n",
    "    cm2lbl[(cm[0]*256+cm[1])*256+cm[2]] = i # 建立索引\n",
    "\n",
    "def image2label(im):\n",
    "    data = np.array(im, dtype='int32')\n",
    "    idx = (data[:, :, 0] * 256 + data[:, :, 1]) * 256 + data[:, :, 2]\n",
    "    return np.array(cm2lbl[idx], dtype='int64') # 根据索引得到 label 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_transforms(im, label):\n",
    "    im_tfs = tfs.Compose([\n",
    "        tfs.Resize((800, 600)),\n",
    "        tfs.ToTensor(),\n",
    "        tfs.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    im = im_tfs(im)\n",
    "    label = label.resize((600, 800))\n",
    "    label = image2label(label)\n",
    "    label = torch.from_numpy(label)\n",
    "    return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCSegDataset(Dataset):\n",
    "    '''\n",
    "    voc dataset\n",
    "    '''\n",
    "    def __init__(self, train, transforms, data_list,data_path, label_list, label_path):\n",
    "        self.transforms = transforms\n",
    "        self.data_list = data_list\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.label_list = label_list\n",
    "        print('Read ' + str(len(self.data_list)) + ' images')\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data_list[idx]\n",
    "        label = self.label_list[idx]\n",
    "        img = Image.open(self.data_path + img)\n",
    "        label = Image.open(self.label_path + label).convert('RGB')\n",
    "        img, label = self.transforms(img, label)\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 2001 images\n",
      "Read 854 images\n"
     ]
    }
   ],
   "source": [
    "train_data_list = os.listdir('./train_image')\n",
    "train_data_path = './train_image/'\n",
    "train_label_list = os.listdir('./train_label')\n",
    "train_label_path = './train_label/'\n",
    "\n",
    "test_data_list = os.listdir('./test_image')\n",
    "test_data_path = './test_image/'\n",
    "test_label_list = os.listdir('./test_label')\n",
    "test_label_path = './test_label/'\n",
    "voc_train = VOCSegDataset(True, img_transforms, train_data_list, train_data_path, train_label_list, train_label_path)\n",
    "voc_test = VOCSegDataset(False, img_transforms, test_data_list, test_data_path, test_label_list, test_label_path)\n",
    "\n",
    "train_data = DataLoader(voc_train, 2, shuffle=True)\n",
    "test_data = DataLoader(voc_test, 4, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, 1, 1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.max_pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
    "        self.max_pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, 1, 1)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(256)\n",
    "        self.max_pool3 = nn.MaxPool2d(2, 2)\n",
    "        ##self.demax1 = nn.MaxUnpool2d(2, 2)\n",
    "        self.deconv1 = nn.ConvTranspose2d(256, 128, 4, 2, 1)\n",
    "        self.debatch1 = nn.BatchNorm2d(128)\n",
    "        #self.demax2 = nn.MaxUnpool2d(2, 2)\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, 4, 2, 1)\n",
    "        self.debatch2 = nn.BatchNorm2d(64)\n",
    "        #self.demax3 = nn.MaxUnpool2d(2, 2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, 32, 4, 2, 1)\n",
    "        self.debatch3 = nn.BatchNorm2d(32)\n",
    "        self.classifier = nn.Conv2d(32, 21, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x1 = x\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.max_pool3(x)\n",
    "        #x = self.demax1(x)\n",
    "        x = self.deconv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.debatch1(x)\n",
    "        #x = self.demax2(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.debatch2(x)\n",
    "        x = x + x1\n",
    "        #x = self.demax3(x)\n",
    "        x = self.deconv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.debatch3(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_net = FCN().cuda()\n",
    "optimizer = torch.optim.SGD(fcn_net.parameters(), lr = 0.01)\n",
    "criterion = nn.NLLLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fast_hist(label_true, label_pred, n_class):\n",
    "    mask = (label_true >= 0) & (label_true < n_class)\n",
    "    hist = np.bincount(\n",
    "        n_class * label_true[mask].astype(int) +\n",
    "        label_pred[mask], minlength=n_class ** 2).reshape(n_class, n_class)\n",
    "    return hist\n",
    "\n",
    "\n",
    "def label_accuracy_score(label_trues, label_preds, n_class):\n",
    "    \"\"\"Returns accuracy score evaluation result.\n",
    "      - overall accuracy\n",
    "      - mean accuracy\n",
    "      - mean IU\n",
    "      - fwavacc\n",
    "    \"\"\"\n",
    "    hist = np.zeros((n_class, n_class))\n",
    "    for lt, lp in zip(label_trues, label_preds):\n",
    "        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n",
    "    acc = np.diag(hist).sum() / hist.sum()\n",
    "    acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
    "    acc_cls = np.nanmean(acc_cls)\n",
    "    iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "    mean_iu = np.nanmean(iu)\n",
    "    freq = hist.sum(axis=1) / hist.sum()\n",
    "    fwavacc = (freq[freq > 0] * iu[freq > 0]).sum()\n",
    "    return acc, acc_cls, mean_iu, fwavacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.89719, Train Acc: 0.87133, Train Mean IU: 0.04453, Valid Loss: 0.57641, Valid Acc: 0.90609, Valid Mean IU: 0.04989 Time: 0:7:46\n",
      "Epoch: 1, Train Loss: 0.55755, Train Acc: 0.90778, Train Mean IU: 0.04908, Valid Loss: 0.56266, Valid Acc: 0.90618, Valid Mean IU: 0.05046 Time: 0:7:40\n",
      "Epoch: 2, Train Loss: 0.54732, Train Acc: 0.90784, Train Mean IU: 0.05025, Valid Loss: 0.55844, Valid Acc: 0.90643, Valid Mean IU: 0.05087 Time: 0:7:38\n"
     ]
    }
   ],
   "source": [
    "for e in range(3):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_acc_cls = 0\n",
    "    train_mean_iu = 0\n",
    "    train_fwavacc = 0\n",
    "    \n",
    "    prev_time = datetime.now()\n",
    "    net = fcn_net.train()\n",
    "    for data in train_data:\n",
    "        im = data[0].cuda()\n",
    "        label = data[1].cuda()\n",
    "        # forward\n",
    "        out = net(im)\n",
    "        out = F.log_softmax(out, dim=1) # (b, n, h, w)\n",
    "        loss = criterion(out, label)\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data.item()\n",
    "        \n",
    "        label_pred = out.max(dim=1)[1].data.cpu().numpy()\n",
    "        label_true = label.data.cpu().numpy()\n",
    "        for lbt, lbp in zip(label_true, label_pred):\n",
    "            acc, acc_cls, mean_iu, fwavacc = label_accuracy_score(lbt, lbp, 21)\n",
    "            train_acc += acc\n",
    "            train_acc_cls += acc_cls\n",
    "            train_mean_iu += mean_iu\n",
    "            train_fwavacc += fwavacc\n",
    "        \n",
    "    net = fcn_net.eval()\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    eval_acc_cls = 0\n",
    "    eval_mean_iu = 0\n",
    "    eval_fwavacc = 0\n",
    "    for data in test_data:\n",
    "        im = data[0].cuda()\n",
    "        label = data[1].cuda()\n",
    "        # forward\n",
    "        out = net(im)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        loss = criterion(out, label)\n",
    "        eval_loss += loss.data.item()\n",
    "        \n",
    "        label_pred = out.max(dim=1)[1].data.cpu().numpy()\n",
    "        label_true = label.data.cpu().numpy()\n",
    "        for lbt, lbp in zip(label_true, label_pred):\n",
    "            acc, acc_cls, mean_iu, fwavacc = label_accuracy_score(lbt, lbp, 21)\n",
    "            eval_acc += acc\n",
    "            eval_acc_cls += acc_cls\n",
    "            eval_mean_iu += mean_iu\n",
    "            eval_fwavacc += fwavacc\n",
    "        \n",
    "    cur_time = datetime.now()\n",
    "    h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "    m, s = divmod(remainder, 60)\n",
    "    epoch_str = ('Epoch: {}, Train Loss: {:.5f}, Train Acc: {:.5f}, Train Mean IU: {:.5f}, \\\n",
    "Valid Loss: {:.5f}, Valid Acc: {:.5f}, Valid Mean IU: {:.5f} '.format(\n",
    "        e, train_loss / len(train_data), train_acc / len(voc_train), train_mean_iu / len(voc_train),\n",
    "        eval_loss / len(test_data), eval_acc / len(voc_test), eval_mean_iu / len(voc_test)))\n",
    "    time_str = 'Time: {:.0f}:{:.0f}:{:.0f}'.format(h, m, s)\n",
    "    print(epoch_str + time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
