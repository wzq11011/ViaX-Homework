{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as tfs\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf = tfs.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ImageFolder('./Fruit-Images-Dataset/Training', transform = data_tf)\n",
    "test_set = ImageFolder('./Fruit-Images-Dataset/Test', transform = data_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(train_set, batch_size = 64, shuffle = True)\n",
    "test_data = DataLoader(test_set, batch_size = 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
    "        self.max_pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
    "        self.max_pool2 = nn.MaxPool2d(2 ,2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding = 1)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(128)\n",
    "        self.max_pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3)\n",
    "        self.batch_norm4 = nn.BatchNorm2d(256)\n",
    "        self.max_pool4 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(6400, 3200)\n",
    "        self.fc2 = nn.Linear(3200, 1600)\n",
    "        self.fc3 = nn.Linear(1600, 101)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.max_pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.max_pool4(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = conv_net1()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_learning_rate(optimizer, lr):\n",
    "    for param_groups in optimizer.param_groups:\n",
    "        param_groups['lr'] = lr\n",
    "        \n",
    "def get_acc(output, label):\n",
    "    total = output.shape[0]\n",
    "    _, pred_label = output.max(1)\n",
    "    num_correct = (pred_label == label).sum().data.item()\n",
    "    return num_correct / total\n",
    "\n",
    "def train(net, train_data, test_data, epoch, optimizer, criterion):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    if torch.cuda.is_available():\n",
    "        net = net.cuda()\n",
    "    prev_time = datetime.now()\n",
    "    for epoch in range(epoch):\n",
    "        if epoch == 15:\n",
    "            set_learning_rate(optimizer, 0.001)\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        net = net.train()\n",
    "        for im, labels in train_data:\n",
    "            if torch.cuda.is_available():\n",
    "                im = im.cuda()\n",
    "                labels = labels.cuda()\n",
    "            \n",
    "            output = net(im)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.data.item()\n",
    "            train_acc += get_acc(output, labels)\n",
    "        cur_time = datetime.now()\n",
    "        h,remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m,s = divmod(remainder, 60)\n",
    "        time_str = 'Time:%02d:%02d:%02d'%(h, m, s)\n",
    "        \n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        net = net.eval()\n",
    "        for im, labels in test_data:\n",
    "            if torch.cuda.is_available():\n",
    "                im = im.cuda()\n",
    "                labels = labels.cuda()\n",
    "            output = net(im)\n",
    "            loss = criterion(output, labels)\n",
    "            test_loss += loss.data.item()\n",
    "            test_acc += get_acc(output, labels)\n",
    "        epoch_str = (\n",
    "                \"Epoch %d. Train Loss: %f, Train Acc: %f, Valid Loss: %f, Valid Acc: %f, \"\n",
    "                % (epoch, train_loss / len(train_data),\n",
    "                   train_acc / len(train_data), test_loss / len(test_data),\n",
    "                   test_acc / len(test_data)))\n",
    "        prev_time = cur_time\n",
    "        train_losses.append(train_loss / len(train_data))\n",
    "        test_losses.append(test_loss / len(test_data))\n",
    "        print(epoch_str + time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train Loss: 3.175397, Train Acc: 0.726502, Valid Loss: 1.510375, Valid Acc: 0.713308, Time:00:01:22\n",
      "Epoch 1. Train Loss: 0.330226, Train Acc: 0.911587, Valid Loss: 0.910819, Valid Acc: 0.810138, Time:00:01:44\n",
      "Epoch 2. Train Loss: 0.308968, Train Acc: 0.927269, Valid Loss: 0.972013, Valid Acc: 0.861778, Time:00:01:41\n",
      "Epoch 3. Train Loss: 0.278857, Train Acc: 0.938740, Valid Loss: 1.427092, Valid Acc: 0.823828, Time:00:01:42\n",
      "Epoch 4. Train Loss: 0.170069, Train Acc: 0.963058, Valid Loss: 0.651804, Valid Acc: 0.907979, Time:00:01:44\n",
      "Epoch 5. Train Loss: 0.143462, Train Acc: 0.972128, Valid Loss: 0.603411, Valid Acc: 0.917320, Time:00:01:42\n",
      "Epoch 6. Train Loss: 0.251222, Train Acc: 0.952554, Valid Loss: 1.168884, Valid Acc: 0.831028, Time:00:01:44\n",
      "Epoch 7. Train Loss: 0.087363, Train Acc: 0.981045, Valid Loss: 0.555847, Valid Acc: 0.917996, Time:00:01:44\n",
      "Epoch 8. Train Loss: 0.104398, Train Acc: 0.977749, Valid Loss: 0.418779, Valid Acc: 0.942010, Time:00:01:38\n",
      "Epoch 9. Train Loss: 0.041009, Train Acc: 0.990301, Valid Loss: 0.261917, Valid Acc: 0.964188, Time:00:01:41\n",
      "Epoch 10. Train Loss: 0.007344, Train Acc: 0.997704, Valid Loss: 0.593789, Valid Acc: 0.926311, Time:00:01:41\n",
      "Epoch 11. Train Loss: 0.166565, Train Acc: 0.969851, Valid Loss: 0.489928, Valid Acc: 0.943829, Time:00:01:38\n",
      "Epoch 12. Train Loss: 0.062467, Train Acc: 0.986643, Valid Loss: 0.484507, Valid Acc: 0.934138, Time:00:01:41\n",
      "Epoch 13. Train Loss: 0.076261, Train Acc: 0.984582, Valid Loss: 0.967208, Valid Acc: 0.893287, Time:00:01:40\n",
      "Epoch 14. Train Loss: 0.334060, Train Acc: 0.943960, Valid Loss: 0.652939, Valid Acc: 0.918653, Time:00:01:38\n",
      "Epoch 15. Train Loss: 0.013584, Train Acc: 0.996265, Valid Loss: 0.247262, Valid Acc: 0.961744, Time:00:01:40\n",
      "Epoch 16. Train Loss: 0.003712, Train Acc: 0.999104, Valid Loss: 0.229641, Valid Acc: 0.965540, Time:00:01:43\n",
      "Epoch 17. Train Loss: 0.002035, Train Acc: 0.999414, Valid Loss: 0.250709, Valid Acc: 0.964684, Time:00:01:39\n",
      "Epoch 18. Train Loss: 0.002309, Train Acc: 0.999409, Valid Loss: 0.239987, Valid Acc: 0.962940, Time:00:01:40\n",
      "Epoch 19. Train Loss: 0.001879, Train Acc: 0.999543, Valid Loss: 0.229679, Valid Acc: 0.964854, Time:00:01:40\n",
      "Epoch 20. Train Loss: 0.000797, Train Acc: 0.999886, Valid Loss: 0.228103, Valid Acc: 0.966676, Time:00:01:39\n",
      "Epoch 21. Train Loss: 0.000948, Train Acc: 0.999867, Valid Loss: 0.217829, Valid Acc: 0.967295, Time:00:01:37\n",
      "Epoch 22. Train Loss: 0.001334, Train Acc: 0.999619, Valid Loss: 0.244260, Valid Acc: 0.966835, Time:00:01:41\n",
      "Epoch 23. Train Loss: 0.000996, Train Acc: 0.999752, Valid Loss: 0.249493, Valid Acc: 0.968088, Time:00:01:41\n",
      "Epoch 24. Train Loss: 0.001485, Train Acc: 0.999638, Valid Loss: 0.237190, Valid Acc: 0.967179, Time:00:01:40\n"
     ]
    }
   ],
   "source": [
    "train(net, train_data, test_data, 25, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_net2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.max_pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding = 1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
    "        self.max_pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, padding = 1)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(256)\n",
    "        self.max_pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.conv4 = nn.Conv2d(256, 512, 3)\n",
    "        self.batch_norm4 = nn.BatchNorm2d(512)\n",
    "        self.max_pool4 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(12800, 6400)\n",
    "        self.fc2 = nn.Linear(6400, 3200)\n",
    "        self.fc3 = nn.Linear(3200, 1600)\n",
    "        self.fc4 = nn.Linear(1600, 101)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.max_pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.max_pool4(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = conv_net2()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train Loss: 25.574792, Train Acc: 0.093941, Valid Loss: 4.352253, Valid Acc: 0.031126, Time:00:01:42\n",
      "Epoch 1. Train Loss: 4.136753, Train Acc: 0.071922, Valid Loss: 4.032511, Valid Acc: 0.066206, Time:00:02:06\n",
      "Epoch 2. Train Loss: 3.889701, Train Acc: 0.096841, Valid Loss: 3.765036, Valid Acc: 0.120186, Time:00:02:05\n",
      "Epoch 3. Train Loss: 3.821041, Train Acc: 0.124271, Valid Loss: 3.495181, Valid Acc: 0.146182, Time:00:02:05\n",
      "Epoch 4. Train Loss: 3.295712, Train Acc: 0.216328, Valid Loss: 3.012486, Valid Acc: 0.216269, Time:00:02:05\n",
      "Epoch 5. Train Loss: 2.414540, Train Acc: 0.367779, Valid Loss: 2.283053, Valid Acc: 0.402435, Time:00:02:06\n",
      "Epoch 6. Train Loss: 1.928114, Train Acc: 0.480827, Valid Loss: 2.192950, Valid Acc: 0.418152, Time:00:02:06\n",
      "Epoch 7. Train Loss: 1.609250, Train Acc: 0.545399, Valid Loss: 1.555637, Valid Acc: 0.558167, Time:00:02:06\n",
      "Epoch 8. Train Loss: 1.302749, Train Acc: 0.611489, Valid Loss: 1.778664, Valid Acc: 0.530773, Time:00:02:06\n",
      "Epoch 9. Train Loss: 1.046369, Train Acc: 0.675474, Valid Loss: 1.555148, Valid Acc: 0.650774, Time:00:02:06\n",
      "Epoch 10. Train Loss: 1.004772, Train Acc: 0.694411, Valid Loss: 1.260512, Valid Acc: 0.654426, Time:00:02:06\n",
      "Epoch 11. Train Loss: 0.886961, Train Acc: 0.734154, Valid Loss: 1.080215, Valid Acc: 0.693688, Time:00:02:05\n",
      "Epoch 12. Train Loss: 0.587771, Train Acc: 0.810149, Valid Loss: 0.784242, Valid Acc: 0.781163, Time:00:02:07\n",
      "Epoch 13. Train Loss: 0.853636, Train Acc: 0.753584, Valid Loss: 1.445587, Valid Acc: 0.653015, Time:00:02:04\n",
      "Epoch 14. Train Loss: 0.535245, Train Acc: 0.819362, Valid Loss: 0.906305, Valid Acc: 0.770370, Time:00:02:04\n",
      "Epoch 15. Train Loss: 0.319902, Train Acc: 0.888173, Valid Loss: 0.538082, Valid Acc: 0.858701, Time:00:02:03\n",
      "Epoch 16. Train Loss: 0.276525, Train Acc: 0.903597, Valid Loss: 0.518246, Valid Acc: 0.872291, Time:00:02:05\n",
      "Epoch 17. Train Loss: 0.258953, Train Acc: 0.910305, Valid Loss: 0.508409, Valid Acc: 0.864163, Time:00:02:03\n",
      "Epoch 18. Train Loss: 0.253709, Train Acc: 0.910682, Valid Loss: 0.491033, Valid Acc: 0.879095, Time:00:02:04\n",
      "Epoch 19. Train Loss: 0.255970, Train Acc: 0.910130, Valid Loss: 0.524241, Valid Acc: 0.864472, Time:00:02:01\n",
      "Epoch 20. Train Loss: 0.250833, Train Acc: 0.911839, Valid Loss: 0.475384, Valid Acc: 0.876736, Time:00:02:01\n",
      "Epoch 21. Train Loss: 0.235752, Train Acc: 0.918047, Valid Loss: 0.492329, Valid Acc: 0.877985, Time:00:02:03\n",
      "Epoch 22. Train Loss: 0.228520, Train Acc: 0.919947, Valid Loss: 0.505553, Valid Acc: 0.876650, Time:00:02:01\n",
      "Epoch 23. Train Loss: 0.228418, Train Acc: 0.919008, Valid Loss: 0.476769, Valid Acc: 0.882078, Time:00:02:04\n",
      "Epoch 24. Train Loss: 0.212511, Train Acc: 0.920806, Valid Loss: 0.493303, Valid Acc: 0.879201, Time:00:02:05\n"
     ]
    }
   ],
   "source": [
    "train(net, train_data, test_data, 25, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_net3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride = 2)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.max_pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
    "        self.max_pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(256)\n",
    "        self.max_pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(4096, 2000)\n",
    "        self.fc2 = nn.Linear(2000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 101)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.max_pool3(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net3 = conv_net3()\n",
    "optimizer = torch.optim.Adam(net3.parameters(), lr = 0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train Loss: 1.715153, Train Acc: 0.718586, Valid Loss: 0.668927, Valid Acc: 0.805212, Time:00:01:08\n",
      "Epoch 1. Train Loss: 0.270468, Train Acc: 0.918375, Valid Loss: 0.914820, Valid Acc: 0.825802, Time:00:01:30\n",
      "Epoch 2. Train Loss: 0.215664, Train Acc: 0.940155, Valid Loss: 0.592757, Valid Acc: 0.891869, Time:00:01:35\n",
      "Epoch 3. Train Loss: 0.160126, Train Acc: 0.956714, Valid Loss: 0.656955, Valid Acc: 0.915912, Time:00:01:33\n",
      "Epoch 4. Train Loss: 0.232850, Train Acc: 0.947376, Valid Loss: 1.734532, Valid Acc: 0.752714, Time:00:01:34\n",
      "Epoch 5. Train Loss: 0.125665, Train Acc: 0.967359, Valid Loss: 0.500475, Valid Acc: 0.925076, Time:00:01:36\n",
      "Epoch 6. Train Loss: 0.066225, Train Acc: 0.983065, Valid Loss: 0.345162, Valid Acc: 0.946731, Time:00:01:35\n",
      "Epoch 7. Train Loss: 0.027291, Train Acc: 0.992226, Valid Loss: 0.293368, Valid Acc: 0.950814, Time:00:01:35\n",
      "Epoch 8. Train Loss: 0.030351, Train Acc: 0.991645, Valid Loss: 0.571581, Valid Acc: 0.921619, Time:00:01:35\n",
      "Epoch 9. Train Loss: 0.255189, Train Acc: 0.949814, Valid Loss: 0.400987, Valid Acc: 0.942403, Time:00:01:35\n",
      "Epoch 10. Train Loss: 0.039298, Train Acc: 0.989492, Valid Loss: 0.445257, Valid Acc: 0.945117, Time:00:01:32\n",
      "Epoch 11. Train Loss: 0.103259, Train Acc: 0.977302, Valid Loss: 1.263255, Valid Acc: 0.852940, Time:00:01:34\n",
      "Epoch 12. Train Loss: 0.125613, Train Acc: 0.974725, Valid Loss: 1.031053, Valid Acc: 0.893387, Time:00:01:34\n",
      "Epoch 13. Train Loss: 0.167124, Train Acc: 0.968303, Valid Loss: 0.378269, Valid Acc: 0.946702, Time:00:01:33\n",
      "Epoch 14. Train Loss: 0.040316, Train Acc: 0.990892, Valid Loss: 0.535130, Valid Acc: 0.929669, Time:00:01:35\n",
      "Epoch 15. Train Loss: 0.005933, Train Acc: 0.998342, Valid Loss: 0.272020, Valid Acc: 0.968204, Time:00:01:34\n",
      "Epoch 16. Train Loss: 0.001197, Train Acc: 0.999790, Valid Loss: 0.249268, Valid Acc: 0.973682, Time:00:01:34\n",
      "Epoch 17. Train Loss: 0.000825, Train Acc: 0.999867, Valid Loss: 0.246582, Valid Acc: 0.974698, Time:00:01:31\n",
      "Epoch 18. Train Loss: 0.000923, Train Acc: 0.999757, Valid Loss: 0.253412, Valid Acc: 0.972337, Time:00:01:35\n",
      "Epoch 19. Train Loss: 0.001983, Train Acc: 0.999619, Valid Loss: 0.250549, Valid Acc: 0.974482, Time:00:01:35\n",
      "Epoch 20. Train Loss: 0.000462, Train Acc: 0.999943, Valid Loss: 0.250472, Valid Acc: 0.974765, Time:00:01:35\n",
      "Epoch 21. Train Loss: 0.000456, Train Acc: 0.999867, Valid Loss: 0.246044, Valid Acc: 0.975274, Time:00:01:35\n",
      "Epoch 22. Train Loss: 0.000675, Train Acc: 0.999834, Valid Loss: 0.256504, Valid Acc: 0.974998, Time:00:01:34\n",
      "Epoch 23. Train Loss: 0.002981, Train Acc: 0.999310, Valid Loss: 0.248122, Valid Acc: 0.975101, Time:00:01:32\n",
      "Epoch 24. Train Loss: 0.003412, Train Acc: 0.999139, Valid Loss: 0.257555, Valid Acc: 0.973353, Time:00:01:34\n"
     ]
    }
   ],
   "source": [
    "train(net3, train_data, test_data, 25, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结\n",
    "\n",
    "第一个模型和第三个模型的表现比较类似，第一个模型在第二和第三个conv layer加上了padding = 1，而第三个模型在第一个conv layer上使用了stride = 2。最终两个模型在训练集上都有99.9%的准确率，测试集上大约为96%\n",
    "但是第二个模型的表现就明显和第一个第三个模型的表现相差甚远。我其实并没有改动什么，只是在第一个模型上将filter的数量在每层都翻了一倍，相应的全连接层也多加了一层，但是模型训练却比第一个模型难多了。最终训练集上的表现只有92%的准确率，测试集上只有87%。\n",
    "第二个模型和第一个第三个模型表现差了那么多，我想是因为把每层的filter的数量都增加了一倍，导致卷积层和最后的全连接层要训练的参数变得比第一个模型多了好多，训练难度更大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
