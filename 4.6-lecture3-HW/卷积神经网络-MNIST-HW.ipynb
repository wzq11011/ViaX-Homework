{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "from datetime import datetime\n",
    "from torchvision import transforms as tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tf(x):\n",
    "    data_aug = tfs.Compose([\n",
    "        tfs.RandomHorizontalFlip(),\n",
    "        tfs.ColorJitter(brightness = 0.5, contrast = 0.5, hue = 0.2),\n",
    "        tfs.ToTensor()\n",
    "    ])\n",
    "    x = data_aug(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MNIST('./data', train = True, transform = data_tf, download = True)\n",
    "train_data = DataLoader(train_set, batch_size = 64, shuffle = True)\n",
    "test_set = MNIST('./data', train = False, transform = data_tf, download = True)\n",
    "test_data = DataLoader(test_set, batch_size = 128, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(16)\n",
    "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, 5)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(8)\n",
    "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_learning_rate(optimizer, lr):\n",
    "    for param_groups in optimizer.param_groups:\n",
    "        param_groups['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_data, test_data, epoch, optimizer, criterion):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    if torch.cuda.is_available():\n",
    "        net = net.cuda()\n",
    "    prev_time = datetime.now()\n",
    "    for epoch in range(epoch):\n",
    "        if epoch == 15:\n",
    "            set_learning_rate(optimizer, 0.001)\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        net = net.train()\n",
    "        for im, labels in train_data:\n",
    "            if torch.cuda.is_available():\n",
    "                im = im.cuda()\n",
    "                labels = labels.cuda()\n",
    "            \n",
    "            output = net(im)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.data.item()\n",
    "            train_acc += get_acc(output, labels)\n",
    "        cur_time = datetime.now()\n",
    "        h,remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m,s = divmod(remainder, 60)\n",
    "        time_str = 'Time:%02d:%02d:%02d'%(h, m, s)\n",
    "        \n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        net = net.eval()\n",
    "        for im, labels in test_data:\n",
    "            if torch.cuda.is_available():\n",
    "                im = im.cuda()\n",
    "                labels = labels.cuda()\n",
    "            output = net(im)\n",
    "            loss = criterion(output, labels)\n",
    "            test_loss += loss.data.item()\n",
    "            test_acc += get_acc(output, labels)\n",
    "        epoch_str = (\n",
    "                \"Epoch %d. Train Loss: %f, Train Acc: %f, Valid Loss: %f, Valid Acc: %f, \"\n",
    "                % (epoch, train_loss / len(train_data),\n",
    "                   train_acc / len(train_data), test_loss / len(test_data),\n",
    "                   test_acc / len(test_data)))\n",
    "        prev_time = cur_time\n",
    "        train_losses.append(train_loss / len(train_data))\n",
    "        test_losses.append(test_loss / len(test_data))\n",
    "        print(epoch_str + time_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_net(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (batch_norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (batch_norm2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = conv_net()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(output, label):\n",
    "    total = output.shape[0]\n",
    "    _, pred_label = output.max(1)\n",
    "    num_correct = (pred_label == label).sum().data.item()\n",
    "    return num_correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train Loss: 0.246678, Train Acc: 0.924657, Valid Loss: 0.122760, Valid Acc: 0.963212, Time:00:00:13\n",
      "Epoch 1. Train Loss: 0.116107, Train Acc: 0.964919, Valid Loss: 0.097560, Valid Acc: 0.969047, Time:00:00:14\n",
      "Epoch 2. Train Loss: 0.099157, Train Acc: 0.969883, Valid Loss: 0.088247, Valid Acc: 0.973794, Time:00:00:14\n",
      "Epoch 3. Train Loss: 0.086329, Train Acc: 0.973464, Valid Loss: 0.085094, Valid Acc: 0.972508, Time:00:00:14\n",
      "Epoch 4. Train Loss: 0.079706, Train Acc: 0.975313, Valid Loss: 0.068256, Valid Acc: 0.979628, Time:00:00:14\n",
      "Epoch 5. Train Loss: 0.078043, Train Acc: 0.976779, Valid Loss: 0.069618, Valid Acc: 0.977354, Time:00:00:14\n",
      "Epoch 6. Train Loss: 0.070240, Train Acc: 0.979111, Valid Loss: 0.071891, Valid Acc: 0.979430, Time:00:00:14\n",
      "Epoch 7. Train Loss: 0.068916, Train Acc: 0.979128, Valid Loss: 0.078895, Valid Acc: 0.976562, Time:00:00:14\n",
      "Epoch 8. Train Loss: 0.067113, Train Acc: 0.979894, Valid Loss: 0.061352, Valid Acc: 0.982002, Time:00:00:14\n",
      "Epoch 9. Train Loss: 0.066394, Train Acc: 0.980360, Valid Loss: 0.065197, Valid Acc: 0.981408, Time:00:00:14\n",
      "Epoch 10. Train Loss: 0.060476, Train Acc: 0.981710, Valid Loss: 0.061903, Valid Acc: 0.982298, Time:00:00:14\n",
      "Epoch 11. Train Loss: 0.059957, Train Acc: 0.981610, Valid Loss: 0.068591, Valid Acc: 0.981309, Time:00:00:14\n",
      "Epoch 12. Train Loss: 0.059201, Train Acc: 0.981843, Valid Loss: 0.069628, Valid Acc: 0.982199, Time:00:00:15\n",
      "Epoch 13. Train Loss: 0.059334, Train Acc: 0.981943, Valid Loss: 0.082033, Valid Acc: 0.978145, Time:00:00:14\n",
      "Epoch 14. Train Loss: 0.057369, Train Acc: 0.982209, Valid Loss: 0.069655, Valid Acc: 0.980914, Time:00:00:14\n",
      "Epoch 15. Train Loss: 0.033711, Train Acc: 0.989639, Valid Loss: 0.047959, Valid Acc: 0.985759, Time:00:00:14\n",
      "Epoch 16. Train Loss: 0.029010, Train Acc: 0.991588, Valid Loss: 0.047582, Valid Acc: 0.986452, Time:00:00:14\n",
      "Epoch 17. Train Loss: 0.028407, Train Acc: 0.991421, Valid Loss: 0.045045, Valid Acc: 0.986946, Time:00:00:14\n",
      "Epoch 18. Train Loss: 0.025740, Train Acc: 0.992188, Valid Loss: 0.047934, Valid Acc: 0.986452, Time:00:00:14\n",
      "Epoch 19. Train Loss: 0.024648, Train Acc: 0.992038, Valid Loss: 0.048405, Valid Acc: 0.986551, Time:00:00:14\n",
      "Epoch 20. Train Loss: 0.022863, Train Acc: 0.993104, Valid Loss: 0.048862, Valid Acc: 0.986946, Time:00:00:14\n",
      "Epoch 21. Train Loss: 0.024436, Train Acc: 0.992537, Valid Loss: 0.049895, Valid Acc: 0.986551, Time:00:00:14\n",
      "Epoch 22. Train Loss: 0.022920, Train Acc: 0.992771, Valid Loss: 0.046894, Valid Acc: 0.987935, Time:00:00:14\n",
      "Epoch 23. Train Loss: 0.022710, Train Acc: 0.993170, Valid Loss: 0.045573, Valid Acc: 0.987441, Time:00:00:14\n",
      "Epoch 24. Train Loss: 0.022301, Train Acc: 0.992987, Valid Loss: 0.043413, Valid Acc: 0.987638, Time:00:00:14\n"
     ]
    }
   ],
   "source": [
    "train(net, train_data, test_data, 25, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
