{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms as tfs\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tfs.Compose([\n",
    "    tfs.ToTensor(),\n",
    "    tfs.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class portrait_dataset(Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(os.listdir('image_jpg/img_jpg'))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        im_name = os.listdir('image_jpg/img_jpg')[idx]\n",
    "        img = Image.open('image_jpg/img_jpg/' + im_name)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = MNIST('./data', train = True, transform = transform, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DIM = 7500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self, noise_dim = NOISE_DIM):\n",
    "        super(generator, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "                    nn.ConvTranspose2d(1, 32, 4, 2, 1),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.ConvTranspose2d(32, 32, 4, 2, 1),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.ConvTranspose2d(32, 3, 4, 2, 1),\n",
    "                    nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], 1, 75, 100)\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "                    nn.Conv2d(3, 32, 3, stride = 1),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.BatchNorm2d(32),\n",
    "                    nn.MaxPool2d(2, 2),\n",
    "                    nn.Conv2d(32, 64, 3, stride = 2),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.MaxPool2d(2, 2),\n",
    "                    nn.Conv2d(64, 64, 3, stride = 2),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.MaxPool2d(2, 2),\n",
    "                    nn.Conv2d(64, 64, 3, stride = 2),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.MaxPool2d(2, 2)\n",
    "                    )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(1280, 1000),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(1000, 100),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(100, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss = nn.BCEWithLogitsLoss().cuda()\n",
    "\n",
    "def discriminator_loss(logits_real, logits_fake): # 判别器的 loss\n",
    "    size = logits_real.shape[0]\n",
    "    true_labels = torch.ones(size, 1).float().cuda()\n",
    "    false_labels = torch.zeros(size, 1).float().cuda()\n",
    "    loss = bce_loss(logits_real, true_labels) + bce_loss(logits_fake, false_labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(logits_fake): # 生成器的 loss  \n",
    "    size = logits_fake.shape[0]\n",
    "    true_labels = torch.ones(size, 1).float().cuda()\n",
    "    loss = bce_loss(logits_fake, true_labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # 设置画图的尺寸\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "def show_images(images): # 定义画图工具\n",
    "    images = np.reshape(images, [images.shape[0], -1])\n",
    "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
    "\n",
    "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
    "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
    "    return \n",
    "\n",
    "def preprocess_img(x):\n",
    "    x = tfs.ToTensor()(x)\n",
    "    return (x - 0.5) / 0.5\n",
    "\n",
    "def deprocess_img(x):\n",
    "    return (x + 1.0) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "D_net = nn.DataParallel(discriminator())\n",
    "D_net.to(device)\n",
    "G_net = nn.DataParallel(generator())\n",
    "G_net.to(device)\n",
    "D_net_optim = torch.optim.SGD(D_net.parameters(), lr = 0.01)\n",
    "G_net_optim = torch.optim.SGD(G_net.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dc_gan(D_net, G_net, D_optimizer, G_optimizer, discriminator_loss, generator_loss, show_every = 20,\n",
    "                noise_size=7500, num_epochs=3):\n",
    "    iter_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for x in train_data:\n",
    "            bs = x.shape[0]\n",
    "            # 判别网络\n",
    "            real_data = x.cuda() # 真实数据\n",
    "            logits_real = D_net(real_data) # 判别网络得分\n",
    "            \n",
    "            sample_noise = (torch.rand(bs, noise_size) - 0.5) / 0.5 # -1 ~ 1 的均匀分布\n",
    "            g_fake_seed = sample_noise.cuda()\n",
    "            fake_images = G_net(g_fake_seed) # 生成的假的数据\n",
    "            logits_fake = D_net(fake_images) # 判别网络得分\n",
    "\n",
    "            d_total_error = discriminator_loss(logits_real, logits_fake) # 判别器的 loss\n",
    "            D_optimizer.zero_grad()\n",
    "            d_total_error.backward(retain_graph = True)\n",
    "            D_optimizer.step() # 优化判别网络\n",
    "            \n",
    "            # 生成网络\n",
    "            g_fake_seed = sample_noise.cuda()\n",
    "            fake_images = G_net(g_fake_seed) # 生成的假的数据\n",
    "\n",
    "            gen_logits_fake = D_net(fake_images)\n",
    "            g_error = generator_loss(gen_logits_fake) # 生成网络的 loss\n",
    "            G_optimizer.zero_grad()\n",
    "            g_error.backward()\n",
    "            G_optimizer.step() # 优化生成网络\n",
    "\n",
    "            if (iter_count % show_every == 0):\n",
    "                print('Iter: {}, D: {:.4}, G:{:.4}'.format(iter_count, d_total_error.data.item(), g_error.data.item()))\n",
    "                imgs_numpy = fake_images.data.cpu().numpy()\n",
    "                show_images(imgs_numpy[0:2])\n",
    "                show_images(real_data.data.cpu().numpy()[0:2])\n",
    "                plt.show()\n",
    "                print()\n",
    "            iter_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(dataset, batch_size = 32, shuffle = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dc_gan(D_net, G_net, D_net_optim, G_net_optim, discriminator_loss, generator_loss, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
